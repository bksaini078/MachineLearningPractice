{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bksaini078/MachineLearningPractice/blob/main/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA482cSwxo5d"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "Author: Bhupender Kumar Saini\n",
    "\n",
    "As Mean squared difference between student and teacher model output distribution as consis-tency cost during training student model. Itâ€™s assumed that unlabeled data will be having true distribution same as label data. By adding distribution difference while training, model tries toreduce the difference between student and teacher output distribution. The same distributiondifference has been implemented in VAT regularisation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yH_jzqgtaKZE"
   },
   "source": [
    "# Declaring Libraries \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfSUE5RpeQUA",
    "outputId": "1793b50b-17a1-46d0-c778-c161555cacd8"
   },
   "outputs": [],
   "source": [
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOCj2bQfiLH8"
   },
   "outputs": [],
   "source": [
    "#please install contractions \n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "# import contractions\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import spacy\n",
    "import time\n",
    "import re\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim import utils \n",
    "from gensim.test.utils import get_tmpfile\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import en_core_web_sm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# nlp = en_core_web_sm.load()\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# porter=PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlQXTXLez5Yl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "import tensorflow.keras as tfk\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "#this is to enable eager execution\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "path = '/content/drive/MyDrive/Semi_super/ExperimentFolds/fakehealth/preprocessed/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76Lpuz0gk_DW"
   },
   "source": [
    "# Bert Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7XLM4EqlCHu"
   },
   "outputs": [],
   "source": [
    "import bert\n",
    "import tensorflow_hub as hub\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",trainable=True)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n",
    "def bert_tokenization(articles,max_len):\n",
    "    tokenized_articles=[]\n",
    "    for article in articles:\n",
    "        tk_article_temp= np.array(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(article)[:max_len]))\n",
    "        if len(tk_article_temp) < max_len :\n",
    "            # padding with zeros in the end if the len of article is less than maxlen\n",
    "            tk_article_temp= np.hstack((tk_article_temp, np.zeros(maxlen-len(tk_article_temp))))\n",
    "            tokenized_articles.append(tk_article_temp)\n",
    "        else:\n",
    "            tokenized_articles.append(tk_article_temp)\n",
    "    return tf.convert_to_tensor(tokenized_articles),len(tokenizer.vocab),tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AozvbK25RZ6m"
   },
   "source": [
    "# Noise Creator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uX-fC3dxbzJ6"
   },
   "outputs": [],
   "source": [
    "def instant_noise(x_train, y_train, x_unlabel, n_ratio ):\n",
    "    '''this function introduce noise in the training data for mean teacher model , \n",
    "    this function is used in calculating classification cost, user have to provide \n",
    "    amount of noise, want to add(ratio) in train data and test train split ratio too'''\n",
    "    #amount of noise need to add in x_train data \n",
    "    noise=int(np.shape(x_train)[0]*n_ratio)\n",
    " \n",
    "    # taking column of x_train, need it later \n",
    "    x_column = np.shape(x_train)[1]\n",
    "\n",
    "    if noise <= int(np.shape(x_unlabel)[0]):\n",
    "\n",
    "        #taking number of noise from unlabel data \n",
    "        ratio_noise = x_unlabel[:noise]\n",
    "\n",
    "        # creating -1 label for noise data \n",
    "        y_unlabel=np.full((np.shape(ratio_noise)[0], 2), -1)\n",
    "\n",
    "        # adding noise in train data \n",
    "        x = np.append(x_train, ratio_noise, axis=0)\n",
    "        # print(np.shape(x))\n",
    "        y = np.append(y_train, y_unlabel, axis=0)\n",
    "        x = np.append(x,y, axis=1)\n",
    "        x= x[noise:]\n",
    "        row = np.shape(x)[0]\n",
    "\n",
    "        # shufflin data \n",
    "        x =np.random.permutation(x)\n",
    "        # print(np.shape(x))\n",
    "\n",
    "        #seperating label from x \n",
    "        y_train_n=np.reshape(x[:,x_column],(row,1))\n",
    "        x_train_n=x[0:len(x),0:x_column]\n",
    "        # y_train_n= np.reshape(y[:len(x),0],(train_split,1))\n",
    "\n",
    "        \n",
    "    else :\n",
    "        print('error: Insufficient unlabel data available !')\n",
    "\n",
    "    return x_train_n, y_train_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swtc3CtsvXH5"
   },
   "source": [
    "# Model Declaration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFjsH6yzgB4V"
   },
   "outputs": [],
   "source": [
    "def BiLstmModel(maxlen, vocab_size):\n",
    "    tf.keras.backend.clear_session()\n",
    "    inputs = keras.Input(shape=(maxlen,))\n",
    "    x =Embedding(vocab_size, 128, input_length=None)(inputs)\n",
    "    x =Bidirectional(LSTM(128))(x)\n",
    "#   x = Dropout(0.2)(x)\n",
    "#   x =Dense(64,activation='relu')(x)\n",
    "    x =Dense(64)(x)\n",
    "    x =Dense(32)(x)\n",
    "    x =Dense(2, activation='sigmoid')(x)\n",
    "    return Model(inputs,x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrpTHBDBb4Uv"
   },
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QR5z1R9C2big"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Function to create confusion matrix \n",
    "def Confusion_matrix(model,x_test,y_true, threshold, caption='Confusion matrix'):\n",
    "    '''this function will create confusion matrix with predicted value and true label'''\n",
    "    y_hat= model.predict(x_test)\n",
    "    y_pred=(np.greater_equal(y_hat,threshold)).astype(int)\n",
    "    cm=confusion_matrix(y_true,y_pred)\n",
    "    # print(cm)\n",
    "    # calculating recall , precision and f1 score \n",
    "    tp_and_fp=np.sum(cm[:,1])\n",
    "    tn_and_fp=np.sum(cm[0,:])\n",
    "    tp_and_fn = np.sum(cm[1, : ])\n",
    "    tp_and_tn= np.trace(cm)\n",
    "    tp=(tp_and_fp-tn_and_fp+tp_and_tn)/2\n",
    "    '''handling with divide by zero is pending'''\n",
    "    #TODO: handling of divide by zero \n",
    "    precision=tp/tp_and_fp \n",
    "    recall = tp/tp_and_fn\n",
    "    accuracy= np.trace(cm)/np.sum(cm)\n",
    "    # f1_score=sklearn.metrics.f1_score(y_true, y_pred)\n",
    "    f1_score= (2*precision*recall)/(precision+recall)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('f1 Score:', f1_score)\n",
    "    print('Accuracy:', accuracy)\n",
    "\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # figure = plt.figure(figsize=(8, 8))\n",
    "    # # cm=np.around(cm.astype(int))\n",
    "    # # con_mat_norm = np.around(cm, decimals=4)\n",
    "    # con_mat_norm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    # sns.heatmap(con_mat_norm, annot=True,cmap=plt.cm.Oranges)\n",
    "    # plt.tight_layout()\n",
    "    # plt.ylabel('True label')\n",
    "    # plt.xlabel('Predicted label')\n",
    "    # plt.title(caption)\n",
    "    \n",
    "    # plt.show()\n",
    "    return cm, accuracy, precision, recall, f1_score\n",
    "def prec_rec_f1score(y_true,x_test,model):\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn import metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    y_hat= model.predict(x_test)\n",
    "    y_pred=tf.argmax(y_hat,1)\n",
    "    y_true=tf.argmax(y_true,1)\n",
    "    # y_pred=(np.greater_equal(y_hat,0.51)).astype(int)\n",
    "\n",
    "    pr_re_f1score_perclass= precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    pr_re_f1score_average=precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    precision=precision_score(y_true,y_pred,average=None)\n",
    "    recall = recall_score(y_true,y_pred,average=None)\n",
    "    accuracy= accuracy_score(y_true,y_pred)\n",
    "    f1_score=f1_score(y_true,y_pred)\n",
    "    #per class\n",
    "    precision_true=pr_re_f1score_perclass[0][1]\n",
    "    precision_fake=pr_re_f1score_perclass[0][0]\n",
    "    recall_true=pr_re_f1score_perclass[1][1]\n",
    "    recall_fake=pr_re_f1score_perclass[1][0]\n",
    "    f1score_true= pr_re_f1score_perclass[2][1]\n",
    "    f1score_fake= pr_re_f1score_perclass[2][0]\n",
    "\n",
    "    # AUC\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred, pos_label=None)\n",
    "    AUC= metrics.auc(fpr, tpr)\n",
    "\n",
    "    metrices_name=['accuracy','precision_true','precision_fake','recall_true','recall_fake','f1score_true','f1score_fake', 'AUC']\n",
    "    metrices_value=[accuracy, precision_true, precision_fake, recall_true, recall_fake, f1score_true, f1score_fake, AUC]\n",
    "    i=0\n",
    "    for item in metrices_name:\n",
    "        print(item +':' ,metrices_value[i])\n",
    "        i+=1\n",
    "\n",
    "    return accuracy, precision_true, precision_fake, recall_true, recall_fake, f1score_true, f1score_fake, AUC \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYaio-ylcL3b"
   },
   "source": [
    "# Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3YuD3mOcO4v"
   },
   "outputs": [],
   "source": [
    "# declaring loss function\n",
    "# ref:https://github.com/CuriousAI/mean-teacher/tree/master/tensorflow/mean_teacher  updated according to our need .\n",
    "def classification_costs(logits, labels):\n",
    "    \"\"\" Commputing classification cost , after removing labels -1 of unlabelled data and then calculating \n",
    "    the binary cross entropy .\n",
    "    \"\"\"\n",
    "    applicable = tf.not_equal(labels, -1)\n",
    "\n",
    "     # Change -1s to zeros to make cross-entropy computable\n",
    "    labels = tf.where(applicable, labels, tf.zeros_like(labels))\n",
    "\n",
    "    # This will now have incorrect values for unlabeled examples\n",
    "    per_sample = tf.keras.losses.binary_crossentropy(labels,logits)\n",
    "    # Retain costs only for labeled\n",
    "    per_sample = tf.where(applicable, per_sample, tf.zeros_like(per_sample))\n",
    "    # Take mean over all examples, not just labeled examples.\n",
    "   \n",
    "    loss = tf.math.divide( tf.reduce_mean(tf.reduce_sum(per_sample)), np.shape(per_sample)[0])\n",
    "\n",
    "    return loss\n",
    "\n",
    "#custom loss function\n",
    "def Overall_Cost(classification_cost, consistency_cost, ratio=0.5):\n",
    "    return (ratio * classification_cost) + ((1 - ratio)*consistency_cost)\n",
    "#function for consistency cost \n",
    "def Consistency_Cost(teacher_output, student_output):\n",
    "    #Kl divergence \n",
    "    # kl = tf.keras.losses.KLDivergence()\n",
    "    # sq_diff_layer=kl(teacher_output, student_output).numpy()\n",
    "    \n",
    "    #MSE\n",
    "    sq_diff_layer = tf.reduce_mean(tf.math.squared_difference(teacher_output, student_output))\n",
    "    return sq_diff_layer\n",
    "def ema(student_model, teacher_model, alpha):\n",
    "    '''\n",
    "    Calculates the exponential moving average of the student model weights and updates the teacher model weights\n",
    "    formula:\n",
    "    t_i = alpha * t_{i-1} + (1 - alpha) * s_i, with default alpha = 0.99\n",
    "    t_i = weights of teacher model in current epoch\n",
    "    s_i = weights of student model in current epoch\n",
    "    '''\n",
    "    #taking weights \n",
    "    student_weights = student_model.get_weights()\n",
    "    teacher_weights = teacher_model.get_weights()\n",
    "\n",
    "    #length must be equal otherwise it will not work \n",
    "    assert len(student_weights) == len(teacher_weights), 'length of student and teachers weights are not equal Please check. \\n Student: {}, \\n Teacher:{}'.format(\n",
    "        len(student_weights), len(teacher_weights))\n",
    "\n",
    "    new_layers = []\n",
    "    for i, layers in enumerate(student_weights):\n",
    "        new_layer = alpha*(teacher_weights[i]) + (1-alpha)*layers\n",
    "        new_layers.append(new_layer)\n",
    "    teacher_model.set_weights(new_layers)\n",
    "    return teacher_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJqtMkOXbi3s"
   },
   "source": [
    "# Writing Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIF13BPMbm3n"
   },
   "outputs": [],
   "source": [
    "\n",
    "def report_writing(Model,lr,Batch_Size, Epoch,Alpha,Ratio, train_accuracy,test_accuracy,precision_true,precision_fake,recall_true,recall_fake,f1score_true,f1score_fake,AUC,comment):\n",
    "    x = datetime.datetime.now()\n",
    "    report_df = pd.DataFrame(columns=['Date', 'Model','Learning Rate','Batch_Size', 'Epoch','Alpha','Ratio','Train_Accuracy',\n",
    "                                      'Test_Accuracy', 'Precision_True','Precision_Fake','Recall_True','Recall_Fake','F1_Score_True','F1_Score_Fake','AUC',\n",
    "                                      'comment'])\n",
    "    report_df = report_df.append({'Date' : x.strftime(\"%c\"), 'Model' :Model,'Learning Rate':lr,'Batch_Size' : Batch_Size, 'Epoch': Epoch,'Alpha': Alpha,'Ratio': Ratio,'Train_Accuracy': train_accuracy,\n",
    "                                  'Test_Accuracy': test_accuracy, 'Precision_True': precision_true,'Precision_Fake': precision_fake,'Recall_True': recall_true,'Recall_Fake': recall_fake,'F1_Score_True': f1score_true,'F1_Score_Fake': f1score_fake, 'AUC':AUC,'comment': comment}, ignore_index=True)\n",
    "    my_file = Path(path+report_name)\n",
    "\n",
    "    if my_file.exists():\n",
    "        report_df.to_csv(path+report_name,mode='a', header= False , index = False)\n",
    "    else:\n",
    "        report_df.to_csv(path+report_name,mode='w', header= True , index= False) \n",
    "    return \n",
    "\n",
    "# report_writing('Supervised-BiLstm', 124,10,34, 0.5, 0.99,0.90,0.90,0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt6qGg9JOUFI"
   },
   "source": [
    "# Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGh0wEpCz7wo"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_supervised(epochs, batch_size, lr, x_train, y_train, x_val, y_val,x_test, y_test,maxlen,vocab_size):\n",
    "\n",
    "    model_supervised = BiLstmModel(maxlen, vocab_size)\n",
    "    model_supervised.compile(optimizer= tf.keras.optimizers.Adam(learning_rate= lr ),loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "    print('Training supervised Model...')\n",
    "    history=model_supervised.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_val,y_val))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    \n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()  \n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # evaluation\n",
    "    train_accuracy=history.history['accuracy'][len(history.epoch)-1]   \n",
    "    test_accuracy,precision_true,precision_fake,recall_true,recall_fake,f1score_true,f1score_fake, AUC = prec_rec_f1score(y_test,x_test,model_supervised)\n",
    "    # cm, test_accuracy, precision, recall, f1_score =Confusion_matrix(model_supervised,x_test,y_test,0.51, 'Supervised model')\n",
    "    report_writing('Supervised_BILSTM',lr, batch_size,len(history.epoch),'NaN','NaN', train_accuracy, \n",
    "                   test_accuracy, precision_true, precision_fake, recall_true, recall_fake, \n",
    "                   f1score_true, f1score_fake,AUC,'Supervised Learning_bert')   \n",
    "    return model_supervised \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA3VRaeujjfn"
   },
   "source": [
    "\n",
    "# Mean Teacher\n",
    "In this updation takes place during each step/batch. This model doesnt work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zf7EK71Fl-zo"
   },
   "outputs": [],
   "source": [
    "def train_MeanTeacher(epochs, batch_size, alpha, lr, ratio,x_train, y_train,x_val,y_val, x_test, y_test, x_unlabel_tar,vocab_size,maxlen):\n",
    "\n",
    "    #preparing the training dataset\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "    \n",
    "    #preparing the target dataset \n",
    "    tar_dataset =  tf.data.Dataset.from_tensor_slices(x_unlabel_tar)\n",
    "    tar_dataset = tar_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "    #declaring optimiser\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate= lr ) #trying changing learning rate , sometimes it gives good result \n",
    "    train_metrics = tf.keras.metrics.BinaryAccuracy(name='Binary_Accuracy')\n",
    "    val_acc_metric = tf.keras.metrics.BinaryAccuracy(name=\"Binary_Acc\")\n",
    "    teacher_acc_metric = tf.keras.metrics.BinaryAccuracy(name=\"Binary_Acc_teacher\") \n",
    "    # Creating model\n",
    "    student = BiLstmModel(maxlen, vocab_size)\n",
    "    student.compile(optimizer= tf.keras.optimizers.Adam(learning_rate= lr ),loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "    teacher = BiLstmModel(maxlen, vocab_size)\n",
    "    teacher.compile(optimizer= tf.keras.optimizers.Adam(learning_rate= lr ),loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # collecting costs\n",
    "  \n",
    "    train_accuracy=[]\n",
    "    steps=[]\n",
    "\n",
    "    #training teacher with one epoch \n",
    "   \n",
    "    #this I am doing to get all steps details in epoch\n",
    "    i=0\n",
    "    print('Train Mean teacher Model...')\n",
    "    # teacher.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "    teacher.fit(x_train,y_train, batch_size=batch_size, epochs=1)\n",
    "\n",
    "    acc_t=0\n",
    "    #false positive rate and true positive rate\n",
    "    fpr=[]\n",
    "    tpr=[]\n",
    "    # x_unlabel_tar= tf.convert_to_tensor(x_unlabel_tar)\n",
    "    for epoch in range(1,epochs+1):  \n",
    "        print(*\"*****************\")\n",
    "        print('Start of epoch %d' % (epoch,))\n",
    "        print(*\"*****************\")\n",
    "        #iteration over batches \n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "             with tf.GradientTape() as tape:\n",
    "         \n",
    "                # adding instant noise\n",
    "                iterator_unlabel = iter(tar_dataset)\n",
    "                x_batch_unlabel = iterator_unlabel.get_next()\n",
    "\n",
    "                '''this is one method of adding -1 label using unlable data'''\n",
    "                x_train_n,y_train_n= instant_noise(x_batch_train,y_batch_train,x_batch_unlabel,0.2)\n",
    "\n",
    "                # Run the forward pass of the layer\n",
    "                logits= student(x_train_n, training= True)  \n",
    "                # logits_acc =  student(x_batch_sn, training= False) \n",
    "\n",
    "                # doing this because then accuracy cannot be calculated\n",
    "                logits_acc= student(x_batch_train, training= True) \n",
    "\n",
    "                # calculating accuracy\n",
    "                train_metrics(y_batch_train,logits_acc)  \n",
    "\n",
    "                #Calculating classification cost \n",
    "                classification_cost = classification_costs(logits,y_train_n)\n",
    "                # classification.append(classification_cost)\n",
    "         \n",
    "                x_train_n1,_ = instant_noise(x_batch_train,y_batch_train,x_batch_unlabel,0.2)\n",
    "                           \n",
    "                tar_teacher = teacher(x_train_n1) #x_batch_train\n",
    "                #  tar_student= student(x_train_n)\n",
    "                consistency_cost= Consistency_Cost(tar_teacher,logits) \n",
    "                # consistency.append(consistency_cost)\n",
    "\n",
    "                overall_cost= Overall_Cost(classification_cost, consistency_cost, ratio=0.5)\n",
    " \n",
    "                #adding loss to student model \n",
    "             grads= tape.gradient(overall_cost, student.trainable_weights)\n",
    "             i=i+1\n",
    "             steps.append(i)\n",
    "   \n",
    "             # the value of the variables to minimize the loss.\n",
    "             optimizer.apply_gradients(zip(grads, student.trainable_weights))\n",
    "             teacher= ema(student, teacher, alpha=alpha)\n",
    "\n",
    "        train_acc = train_metrics.result()\n",
    "        print(alpha)\n",
    "   \n",
    "        #appending training accuracy\n",
    "        train_accuracy.append(train_acc)\n",
    "\n",
    "       \n",
    "            # Reset training metrics at the end of each epoch\n",
    "        train_metrics.reset_states()\n",
    "   \n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        print('*******STUDENT*************')\n",
    "        prec_rec_f1score(y_val,x_val,student)\n",
    "        print('*******TEACHER*************')\n",
    "        prec_rec_f1score(y_val,x_val,teacher)\n",
    "\n",
    "   \n",
    "        if epoch >= 10 and epoch % 5 ==0 :\n",
    "            print('---------------------------STUDENT--------------------------')\n",
    "            test_accuracy,precision_true,precision_fake,recall_true,recall_fake,f1score_true,f1score_fake,AUC = prec_rec_f1score(y_test,x_test,student)\n",
    "            report_writing('Student',lr, batch_size,epoch,alpha,ratio, train_acc.numpy(), \n",
    "                           test_accuracy, precision_true, precision_fake, recall_true, recall_fake, \n",
    "                           f1score_true, f1score_fake,AUC,'MeanTeacher-Attention')  \n",
    "            print('-----------------------------------------------------------------')\n",
    "    \n",
    "            print('---------------------------TEACHER---------------------------------')\n",
    "       \n",
    "            test_accuracy,precision_true,precision_fake,recall_true,recall_fake,f1score_true,f1score_fake,AUC = prec_rec_f1score(y_test,x_test,teacher)\n",
    "            report_writing('Teacher',lr, batch_size,epoch,alpha,ratio, train_acc.numpy(), \n",
    "                           test_accuracy, precision_true, precision_fake, recall_true, recall_fake, \n",
    "                           f1score_true, f1score_fake,AUC,'MeanTeacher-Attention') \n",
    "       \n",
    "            print('-----------------------------------------------------------------')\n",
    "        # if epoch >= 10 and epoch% 5==0 :\n",
    "        #     teacher.save(path+'/model/MT_unlabel_'+str(epoch))    \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    return teacher\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktWjsTuP2DOQ"
   },
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hq6ZEe6bO9n6"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "lr=0.0001\n",
    "batch_size= 64\n",
    "#for mean teacher \n",
    "ratio =0.5\n",
    "alpha=0.99 #(0.90-0.99)\n",
    "maxlen=510"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB_R6O909dtH"
   },
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCmiDBVgtFwg"
   },
   "outputs": [],
   "source": [
    "# report_name='report/BERT.csv'\n",
    "# from keras.utils import to_categorical\n",
    "# for i in range(1):\n",
    "#     print('-------------FOLD Number:---------------',i)\n",
    "#     x_train= np.load(path+'train_'+str(i)+'_x.npy', allow_pickle=True)\n",
    "#     y_train= np.load(path+'train_'+str(i)+'_y.npy', allow_pickle=True)\n",
    "    \n",
    "\n",
    "#     x_val= np.load(path+'dev_'+str(i)+'_x.npy', allow_pickle=True)\n",
    "#     y_val= np.load(path+'dev_'+str(i)+'_y.npy', allow_pickle=True)\n",
    "    \n",
    "\n",
    "#     x_test= np.load(path+'test_x.npy', allow_pickle=True)\n",
    "#     y_test= np.load(path+'test_y.npy', allow_pickle=True)\n",
    "    \n",
    "#     print('train data size:', np.shape(x_train))\n",
    "#     print('train data True/Fake count:', np.count_nonzero(y_train), len(y_train)- np.count_nonzero(y_train))\n",
    "#     print('val data size:', np.shape(x_val))\n",
    "#     print('val data True/Fake count:', np.count_nonzero(y_val), len(y_val)- np.count_nonzero(y_val))\n",
    "\n",
    "#     print('test data size:', np.shape(x_test))\n",
    "#     print('test data True/Fake count:', np.count_nonzero(y_test), len(y_test)- np.count_nonzero(y_test))\n",
    "#     y_train= to_categorical(y_train)\n",
    "#     y_val= to_categorical(y_val)\n",
    "#     y_test= to_categorical(y_test)\n",
    "\n",
    "\n",
    "#     x_train, vocab_size, tokenizer = bert_tokenization(x_train,maxlen)\n",
    "#     x_val, _, _ = bert_tokenization(x_val,maxlen)\n",
    "#     x_test, _, _ = bert_tokenization(x_test,maxlen)\n",
    "#     epochs=6\n",
    "#     model = train_supervised(epochs, batch_size, lr, x_train, y_train, x_val, y_val,x_test, y_test,maxlen,vocab_size)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC-kORjR9wRN"
   },
   "source": [
    "# BERT-MT-Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "uRXdGvMJiA52",
    "outputId": "e7fac6fd-8b62-4bd5-b486-02f053f74f27"
   },
   "outputs": [],
   "source": [
    "report_name='report/BERT-MT-Mix.csv'\n",
    "for i in range(5):\n",
    "    x_train= np.load(path+'train_'+str(i)+'_x.npy', allow_pickle=True)\n",
    "    y_train= np.load(path+'train_'+str(i)+'_y.npy', allow_pickle=True)\n",
    "\n",
    "    x_val= np.load(path+'dev_'+str(i)+'_x.npy', allow_pickle=True)\n",
    "    y_val= np.load(path+'dev_'+str(i)+'_y.npy', allow_pickle=True)\n",
    "\n",
    "    x_test= np.load(path+'test_x.npy', allow_pickle=True)\n",
    "    y_test= np.load(path+'test_y.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "    x_unlabel= np.load(path+'unlabeled_'+'mix'+'_x.npy', allow_pickle=True)\n",
    "    print('train data size:', np.shape(x_train))\n",
    "    print('train data True/Fake count:', np.count_nonzero(y_train), len(y_train)- np.count_nonzero(y_train))\n",
    "    print('val data size:', np.shape(x_val))\n",
    "\n",
    "    print('test data size:', np.shape(x_test))\n",
    "    print('test data True/Fake count:', np.count_nonzero(y_test), len(y_test)- np.count_nonzero(y_test))\n",
    "    y_train= to_categorical(y_train)\n",
    "    y_val= to_categorical(y_val)\n",
    "    y_test= to_categorical(y_test)\n",
    "\n",
    "    x_train, vocab_size, tokenizer = bert_tokenization(x_train,maxlen)\n",
    "    x_val, _, _ = bert_tokenization(x_val,maxlen)\n",
    "    x_test, _, _ = bert_tokenization(x_test,maxlen)\n",
    "    x_unlabel, _, _ = bert_tokenization(x_unlabel[:1500], maxlen)\n",
    "    epochs=20\n",
    "    model = train_MeanTeacher(epochs, batch_size, alpha, lr, ratio,x_train, y_train,x_val,y_val, x_test, y_test, x_unlabel,vocab_size,maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umeCcvhwJy4e",
    "outputId": "ea873c93-f6bd-4767-f3f0-a4637a6ae158"
   },
   "outputs": [],
   "source": [
    "ratio_noise = x_unlabel[:20]\n",
    "\n",
    "        # creating -1 label for noise data \n",
    "y_unlabel=np.full((np.shape(ratio_noise)[0], 2), -1)\n",
    "np.append(y_train, y_unlabel, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLNcYCBx919J"
   },
   "source": [
    "# BERT-MT-All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfdReF8r96nM"
   },
   "outputs": [],
   "source": [
    "report_name='report/BERT-MT-All.csv'\n",
    "for i in range(5):\n",
    "    x_train= np.load(path+'train_'+str(i)+'_x.npy', allow_pickle=True)\n",
    "    y_train= np.load(path+'train_'+str(i)+'_y.npy', allow_pickle=True)\n",
    "\n",
    "    x_val= np.load(path+'dev_'+str(i)+'_x.npy', allow_pickle=True)\n",
    "    y_val= np.load(path+'dev_'+str(i)+'_y.npy', allow_pickle=True)\n",
    "\n",
    "    x_test= np.load(path+'test_x.npy', allow_pickle=True)\n",
    "    y_test= np.load(path+'test_y.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "    x_unlabel= np.load(path+'unlabeled_'+'all'+'_x.npy', allow_pickle=True)\n",
    "\n",
    "    print('train data size:', np.shape(x_train))\n",
    "    print('train data True/Fake count:', np.count_nonzero(y_train), len(y_train)- np.count_nonzero(y_train))\n",
    "    print('val data size:', np.shape(x_val))\n",
    "\n",
    "    print('test data size:', np.shape(x_test))\n",
    "    print('test data True/Fake count:', np.count_nonzero(y_test), len(y_test)- np.count_nonzero(y_test))\n",
    "    y_train= to_categorical(y_train)\n",
    "    y_val= to_categorical(y_val)\n",
    "    y_test= to_categorical(y_test)\n",
    "\n",
    "    x_train, vocab_size, tokenizer = bert_tokenization(x_train,maxlen)\n",
    "    x_val, _, _ = bert_tokenization(x_val,maxlen)\n",
    "    x_test, _, _ = bert_tokenization(x_test,maxlen)\n",
    "    x_unlabel, _, _ = bert_tokenization(x_unlabel[:1500], maxlen)\n",
    "    epochs=20\n",
    "    model = train_MeanTeacher(epochs, batch_size, alpha, lr, ratio,x_train, y_train,x_val,y_val, x_test, y_test, x_unlabel,vocab_size,maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFhDhgwoca3u"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bSirQqcuKXH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYuZi98AucLY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "039e41dFbTlZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "76Lpuz0gk_DW",
    "AozvbK25RZ6m",
    "CrpTHBDBb4Uv",
    "zYaio-ylcL3b",
    "UJqtMkOXbi3s",
    "Xt6qGg9JOUFI",
    "hA3VRaeujjfn",
    "ktWjsTuP2DOQ",
    "jB_R6O909dtH",
    "QC-kORjR9wRN"
   ],
   "include_colab_link": true,
   "name": "BERT.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
